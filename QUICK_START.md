# ğŸš€ Guia RÃ¡pido de InÃ­cio

## âš¡ InÃ­cio RÃ¡pido (3 passos)

### 1. Compilar
```bash
# Windows (PowerShell)
gcc -fopenmp -O3 -march=native -o ompmultmat ompmultmat.c

# Linux/Mac
make
```

### 2. Executar Benchmark
```bash
# Windows
.\run_benchmarks.ps1

# Linux/Mac
chmod +x run_benchmarks.sh
./run_benchmarks.sh
```

### 3. Gerar GrÃ¡ficos
```bash
# Instalar dependÃªncias (apenas uma vez)
pip install matplotlib numpy

# Gerar grÃ¡ficos
python plot_results.py
```

âœ… **Pronto!** Os grÃ¡ficos estarÃ£o salvos como PNG e os resultados em `benchmark_results.txt`

---

## ğŸ“Š O que foi implementado?

O cÃ³digo possui **6 implementaÃ§Ãµes** de multiplicaÃ§Ã£o de matrizes:

| ImplementaÃ§Ã£o | Tipo | Cache | Particionamento | DescriÃ§Ã£o |
|--------------|------|-------|-----------------|-----------|
| `MatMul` | Sequencial | âŒ | - | Baseline (referÃªncia) |
| `MatMulOpenMP` | Paralela | âŒ | 1D | ParalelizaÃ§Ã£o simples |
| `MatMulCache` | Sequencial | âœ… | - | OtimizaÃ§Ã£o de cache |
| `MatMulCacheOpenMP` | Paralela | âœ… | 1D | Paralela + cache |
| **`MatMul2D`** | Paralela | âŒ | **2D** | **Particionamento em blocos** |
| **`MatMul2DCache`** | Paralela | âœ… | **2D** | **Blocos + cache (melhor!)** |

### ğŸ¯ Novidades do Particionamento 2D

- âœ… Divide matrizes em **blocos de 64Ã—64**
- âœ… Melhor uso do **cache L1/L2**
- âœ… **ParalelizaÃ§Ã£o mais eficiente** com schedule dinÃ¢mico
- âœ… **Speedup superior** Ã s implementaÃ§Ãµes 1D
- âœ… VetorizaÃ§Ã£o **SIMD** para performance extra

---

## ğŸ”§ Testes Manuais

### Teste simples (512Ã—512)
```bash
# Windows
echo 512 | .\ompmultmat.exe

# Linux/Mac
echo 512 | ./ompmultmat
```

### Teste com 8 threads
```bash
# Windows
$env:OMP_NUM_THREADS=8
echo 1024 | .\ompmultmat.exe

# Linux/Mac
export OMP_NUM_THREADS=8
echo 1024 | ./ompmultmat
```

### Testar diferentes tamanhos
```bash
# Windows
foreach ($size in 512,1024,2048) { echo $size | .\ompmultmat.exe }

# Linux/Mac
for size in 512 1024 2048; do echo $size | ./ompmultmat; done
```

---

## ğŸ“ˆ Resultados Esperados

Para uma matriz **1024Ã—1024** com **8 threads**:

| ImplementaÃ§Ã£o | Tempo Esperado | Speedup |
|--------------|----------------|---------|
| MatMul (seq) | ~2.5s | 1.0Ã— |
| MatMulOpenMP | ~0.35s | ~7Ã— |
| MatMulCacheOpenMP | ~0.12s | ~20Ã— |
| **MatMul2D** | ~0.10s | ~25Ã— |
| **MatMul2DCache** | **~0.06s** | **~40Ã—** |

> âš ï¸ Valores variam conforme o processador

---

## ğŸ“ Para o RelatÃ³rio

### InformaÃ§Ãµes da MÃ¡quina (Windows)
```powershell
# Copie essas informaÃ§Ãµes
$cpu = Get-WmiObject Win32_Processor
Write-Host "Processador: $($cpu.Name)"
Write-Host "Cores: $($cpu.NumberOfCores)"
Write-Host "Threads: $($cpu.NumberOfLogicalProcessors)"
Write-Host "FrequÃªncia: $($cpu.MaxClockSpeed) MHz"

$ram = [math]::Round((Get-WmiObject Win32_ComputerSystem).TotalPhysicalMemory / 1GB, 2)
Write-Host "RAM: $ram GB"

gcc --version | Select-Object -First 1
```

### InformaÃ§Ãµes da MÃ¡quina (Linux)
```bash
# Copie essas informaÃ§Ãµes
echo "Processador: $(lscpu | grep 'Model name' | cut -d: -f2 | xargs)"
echo "Cores: $(lscpu | grep '^CPU(s):' | cut -d: -f2 | xargs)"
echo "RAM: $(free -h | grep Mem | awk '{print $2}')"
echo "Compilador: $(gcc --version | head -1)"
```

### Use o Template
1. Abra `RELATORIO_TEMPLATE.md`
2. Preencha com suas informaÃ§Ãµes e resultados
3. Converta para PDF:
   ```bash
   pandoc RELATORIO_TEMPLATE.md -o relatorio.pdf --toc
   ```

---

## ğŸ› Troubleshooting

### âŒ "gcc: command not found"
**SoluÃ§Ã£o:** Instale o GCC
- Windows: MinGW-w64 ou MSYS2
- Linux: `sudo apt install build-essential`
- Mac: `xcode-select --install`

### âŒ "undefined reference to omp_get_wtime"
**SoluÃ§Ã£o:** Adicione `-fopenmp` na compilaÃ§Ã£o
```bash
gcc -fopenmp -O3 -march=native -o ompmultmat ompmultmat.c
```

### âŒ Programa muito lento
**SoluÃ§Ãµes:**
1. Certifique-se de usar `-O3` na compilaÃ§Ã£o
2. Teste com matriz menor primeiro (512)
3. Verifique nÃºmero de threads: `echo $env:OMP_NUM_THREADS` (Windows) ou `echo $OMP_NUM_THREADS` (Linux)
4. Feche outros programas

### âŒ "ModuleNotFoundError: No module named 'matplotlib'"
**SoluÃ§Ã£o:**
```bash
pip install matplotlib numpy
# ou
python -m pip install matplotlib numpy
```

### âŒ Resultados inconsistentes
**SoluÃ§Ãµes:**
1. Execute mÃºltiplas vezes e tire a mÃ©dia
2. Feche navegadores e outros programas
3. Conecte o laptop na tomada (evitar throttling)

---

## ğŸ“š Arquivos do Projeto

```
prog-par/
â”œâ”€â”€ ompmultmat.c              # â­ CÃ³digo principal
â”œâ”€â”€ run_benchmarks.ps1        # Script de benchmark (Windows)
â”œâ”€â”€ run_benchmarks.sh         # Script de benchmark (Linux/Mac)
â”œâ”€â”€ plot_results.py           # Gera grÃ¡ficos
â”œâ”€â”€ Makefile                  # Facilita compilaÃ§Ã£o
â”œâ”€â”€ README.md                 # DocumentaÃ§Ã£o completa
â”œâ”€â”€ RELATORIO_TEMPLATE.md     # Template do relatÃ³rio
â”œâ”€â”€ COMANDOS_UTEIS.md         # Comandos Ãºteis
â””â”€â”€ QUICK_START.md           # Este arquivo
```

---

## ğŸ¯ Checklist do Trabalho

- [ ] CÃ³digo compilando sem erros
- [ ] Executar benchmarks (512, 1024, 2048)
- [ ] Testar com 1, 2, 4, 8 threads
- [ ] Gerar grÃ¡ficos com `plot_results.py`
- [ ] Coletar informaÃ§Ãµes da mÃ¡quina
- [ ] Preencher `RELATORIO_TEMPLATE.md`
- [ ] Converter relatÃ³rio para PDF
- [ ] Verificar se MatMul2DCache Ã© o mais rÃ¡pido
- [ ] Analisar speedup e eficiÃªncia
- [ ] Revisar e enviar!

---

## ğŸ’¡ Dicas Finais

### Para Melhor Performance:
1. **Compilar com otimizaÃ§Ã£o mÃ¡xima**: `-O3 -march=native`
2. **Usar nÃºmero correto de threads**: Igual ao nÃºmero de cores fÃ­sicos
3. **Ajustar BLOCK_SIZE**: Teste 32, 64, 128 (edite linhas 123 e 163)
4. **Fechar outros programas**: Evita competiÃ§Ã£o por CPU

### Para o RelatÃ³rio:
1. **Explicar o particionamento 2D**: Use diagramas
2. **Comparar todos os mÃ©todos**: Tabelas e grÃ¡ficos
3. **Analisar speedup**: Por que nÃ£o Ã© linear?
4. **Discutir cache**: Por que i-k-j Ã© melhor que i-j-k?

### Diferencial:
- ğŸŒŸ Testar diferentes BLOCK_SIZE (32, 64, 128)
- ğŸŒŸ Testar diferentes schedules (static, dynamic, guided)
- ğŸŒŸ Adicionar grÃ¡fico de cache misses (com perf, Linux)
- ğŸŒŸ Comparar com BLAS ou NumPy

---

## ğŸ†˜ Precisa de Ajuda?

1. **Leia primeiro:** `README.md` e `COMANDOS_UTEIS.md`
2. **Verifique:** CompilaÃ§Ã£o com `-fopenmp -O3`
3. **Teste:** Com matriz pequena (512) primeiro
4. **Compare:** Seus resultados com os esperados

---

## âœ… VerificaÃ§Ã£o RÃ¡pida

Rode este teste para verificar se estÃ¡ tudo funcionando:

```bash
# Windows
gcc -fopenmp -O3 -march=native -o ompmultmat ompmultmat.c
$env:OMP_NUM_THREADS=4
echo 512 | .\ompmultmat.exe

# Linux/Mac
make
export OMP_NUM_THREADS=4
echo 512 | ./ompmultmat
```

**Deve mostrar:**
```
Matrix size: 512  memory used 1.048576 MB
matMul Time X.XXX s
MatMulOpenMP time X.XXX s
MatMulCacheOptimized time X.XXX s
MatMulCacheOptimizedOpenMP time X.XXX s
MatMul2D (Particionamento 2D sem cache) time X.XXX s
MatMul2DCache (Particionamento 2D com cache) time X.XXX s
```

Se viu essa saÃ­da, **estÃ¡ tudo certo!** ğŸ‰

---

**Boa sorte com o trabalho! ğŸš€**

